{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation of Jaccard score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the path to the CSV file containing Jaccard scores\n",
    "path = Path('../../results/evaluation/Jaccard_score.csv')\n",
    "\n",
    "# Try to read the CSV file into a DataFrame\n",
    "try:\n",
    "    data = pd.read_csv(path)  # Read the CSV file\n",
    "except:\n",
    "    # If reading the file fails (e.g., file not found), print an error message\n",
    "    print('No results to analyze.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Showing data\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Description\n",
    "The dataset presents the Jaccard scores for different clustering algorithms across several images. These clustering algorithms include:\n",
    "\n",
    "1) **KMeans**: A widely-used algorithm that clusters data by partitioning it into a predefined number of clusters (K), aiming to minimize within-cluster variance.\n",
    "2) **MiniBatchKMeans**: A faster variant of KMeans that uses mini-batches to update the centroids, making it more efficient for large datasets.\n",
    "3) **BisectingKMeans**: A hierarchical clustering method that splits clusters iteratively by applying KMeans, generally producing better results for certain data distributions.\n",
    "4) **Birch**: A clustering method designed to handle large datasets efficiently by using a tree structure, grouping data based on proximity.\n",
    "5) **GaussianMixture**: A probabilistic model that assumes data points are generated from a mixture of several Gaussian distributions, useful for handling more complex data structures.\n",
    "\n",
    "Finally, the **Clusterer** column represents the aggregation of all the previous algorithms using a majority voting mechanism. This means that for each image, the algorithm (**Clusterer**) takes the most common clustering result across all the other methods. It serves as an ensemble approach, combining the strengths of each algorithm to improve the overall clustering performance, particularly in cases where individual algorithms might yield conflicting results. In the case of image \"12e.jpg\", for example, the **Clusterer** score is slightly lower than some individual algorithms, suggesting that the majority voting doesn't always result in a better outcome than the best-performing algorithm.\n",
    "\n",
    "The values for the **Clusterer** are consistently in the same range or slightly better than most individual algorithms, highlighting its potential to provide more stable and reliable clustering results through the majority voting mechanism.\n",
    "\n",
    "See the visualization below for a clear comparison of the clustering performance across the algorithms, including the aggregated Clusterer results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# It calculates summary statistics like count, mean, std, min, 25%, 50%, 75%, and max for each numerical column\n",
    "describe = data.describe()\n",
    "\n",
    "# Display the descriptive statistics for inspection\n",
    "describe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Improved visualization for error bars and dashed line plot\n",
    "plt.figure(figsize=(12, 5))  # Set figure size\n",
    "\n",
    "# Plot points with a dashed line and error bars\n",
    "plt.errorbar(\n",
    "    range(len(describe.columns)),\n",
    "    describe.loc['mean'],\n",
    "    yerr=describe.loc['std'],\n",
    "    fmt='o',\n",
    "    linestyle='--',\n",
    "    color='#1f77b4',  # A soft blue color for the line\n",
    "    ecolor='#ff7f0e',  # Orange color for the error bars\n",
    "    capsize=5,\n",
    "    label='Mean Jaccard Score Â± Std Dev'\n",
    ")\n",
    "\n",
    "# Set custom x-ticks to display column labels\n",
    "plt.xticks(\n",
    "    ticks=range(len(describe.columns)),\n",
    "    labels=describe.columns,\n",
    "    rotation=45,\n",
    "    ha='right'  # Rotate and align labels to the right\n",
    ")\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel('Clustering Algorithms', fontsize=12, labelpad=10)\n",
    "plt.ylabel('Mean Jaccard Score', fontsize=12, labelpad=10)\n",
    "plt.title('Performance of Clustering Algorithms\\n(Jaccard Score with Variability)', fontsize=14, pad=15)\n",
    "\n",
    "# Add grid for better readability\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "\n",
    "# Add legend\n",
    "plt.legend(loc='upper right', fontsize=10)\n",
    "\n",
    "# Adjust layout for better spacing\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
